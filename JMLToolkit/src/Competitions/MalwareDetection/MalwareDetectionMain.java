package Competitions.MalwareDetection;

import java.io.File;
import java.io.PrintStream;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Set;

import org.apache.commons.collections.map.HashedMap;

import Utilities.Logging;

public class MalwareDetectionMain 
{
	public static void main(String [] args)
	{
		if (args.length == 0) { 
			
			args = new String[] {  
					"trainFolder=C:\\Users\\josif\\Desktop\\trainBytes",
					"testFolder=C:\\Users\\josif\\Desktop\\testBytes",
					"frequenciesFolder=C:\\Users\\josif\\Desktop\\",
					"wordLength=2"
				};
		}
		
		// the parameters
		String trainFolderPath = "";
		String testFolderPath = "";
		String frequenciesFolderPath = "";
		int wordLength = 2; 
		
		for (String arg : args) {
			String[] argTokens = arg.split("=");
			
			if (argTokens[0].compareTo("trainFolder") == 0)   
				trainFolderPath = argTokens[1];
			else if (argTokens[0].compareTo("testFolder") == 0)   
				testFolderPath = argTokens[1];
			else if (argTokens[0].compareTo("frequenciesFolder") == 0)   
				frequenciesFolderPath = argTokens[1];
			else if (argTokens[0].compareTo("wordLength") == 0)   
				wordLength = Integer.parseInt( argTokens[1] );
		} 
		
		File trainFolder = new File(trainFolderPath);
		File testFolder = new File(testFolderPath);
		
		WordFrequenciesRepresentation mdfe = new WordFrequenciesRepresentation(); 
		
		// the word sizes 
		int [] wordLengths =new int[]{wordLength};
		// compute the dictionaries
		List<Set<String>> dictionaries = mdfe.ComputeDictionary(trainFolder, testFolder, wordLengths);   
		
		// output sizes of dictionaries 
		PrintStream ps = null;
		try{ ps = new PrintStream( frequenciesFolderPath + File.separator + "dictionary.txt"); }
		catch(Exception e){ e.printStackTrace(); }
		
		// convert sets to maps, such that the index can be retreived
		List<Map<String,Integer>> dictionariesMaps  = new ArrayList<Map<String,Integer>>();
		
		// convert the list of dictionary sets to dictionary lists
		for(int wordLengthIdx =0; wordLengthIdx < wordLengths.length; wordLengthIdx++)
		{
			Map<String,Integer> dictMap = new HashMap<String,Integer>();
			
			Iterator<String> dictSetIter = dictionaries.get(wordLengthIdx).iterator();
			int wordIdx = 0;
			while(dictSetIter.hasNext())
			{
				String word = dictSetIter.next();
				dictMap.put(word, wordIdx);
				wordIdx++;
				ps.println(word);
			}
			
			dictionariesMaps.add( dictMap );
			
			System.out.println("Dictionary of word length " + wordLengths[wordLengthIdx] + 
								" has " + wordIdx + " words" ); 
		}
		
		ps.close(); 
		
		// build the term frequency matrix and save the new representations 
		// for the train and test folders into two files under frequenciesFolderPath
		mdfe.ComputeWordFrequencies(trainFolder, testFolder, dictionariesMaps, wordLengths, frequenciesFolderPath);
				
	}

}
